{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Problem Set\n",
    "\n",
    "Through the course of this problem set, you will ........ [fill in later]\n",
    "\n",
    "First, we will import a different dataset from the one we used in our experiments. For simplicity, let's use fashion_mnist since the preprocessing to be done is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and preprocess fashion mnist here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function which implements the LASG-WK2 update condition as detailed in equation 10 of the LASG paper [find cleaner way to refer to the paper]. Follow the prototype detailed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasg_wk2_update(current_weight_grad, last_upload_weight_grad, weights_diff_history, M, c):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        current_weight_grad - ...\n",
    "        last_upload_weight_grad - ...\n",
    "        weights_diff_history - ...\n",
    "        M - ...\n",
    "        c - ...\n",
    "    \n",
    "    Outputs:\n",
    "        Either true or false depending whether the update condition was met.\n",
    "        If true, this means that the worker checking this condition should not upload (and we have saved on communication! yay!)\n",
    "        If false, this means that the worker should upload its model.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice job! You did it, and now you have hopefully gained an understanding of what should be considered when deciding whether a round of communication is worthwhile, as well as how some of the hyperparameters (number of workers and weight vector C) affect the LASG algorithm. \n",
    "\n",
    "Now for something a little more interesting. In practice, we observe that Federated Averaging beats out LASG in most cases. Perform a hyperparameter search to find a case (or multiple cases) wherein LASG beats out Federated Averaging (e.g. reaches the same accuracy with fewer rounds of communication). Comment on the case(s) where this occurs - where might this occur in the real world? Why is Federated Learning useful in such a scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up actually running fed_avg and LASG with hyperparameter specification available for LASG\n",
    "# we shouldn't allow variation of fed_avg hyperparameters so that it remains a constant baseline.\n",
    "# we should include descriptions of what each hyperparameter is so that they know what they are actually varying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For CSCI-6961 Students Only) - Implement the LASG-WK1 Algorithm, detailed in Table 2, Algorithm 1 of the LASG paper. This will require using a different update condition (equation (8) in the paper). You may reference the code we wrote for LASG-WK2 in the lasg_wk2() function in the lasg.py file in the github repository [insert link to that file here]. You will need to make some slight changes, since the algorithms are different.\n",
    "\n",
    "Then, compare the performance of LASG-WK1 and LASG-WK2 on the same dataset with the same hyperparameters. Based on your results, why might you prefer one algorithm over the over?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
